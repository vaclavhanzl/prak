{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bab82522",
   "metadata": {},
   "source": [
    "# Train & Align NN AM using also manually time-aligned data\n",
    "This notebook is like [`NN_Train_Align.ipynb`](NN_Train_Align.ipynb) but uses additional\n",
    "manually time-labeled data. You should already have:\n",
    "* `initial_train_cs.tsv` made by [`Prepare_Training_Data.ipynb`](Prepare_Training_Data.ipynb)\n",
    "* `manual_train.tsv` made by [`Prep_Manual_Train_Data.ipynb`](Prep_Manual_Train_Data.ipynb)\n",
    "\n",
    "In the first iteration, model is trained just on the `manual_train.tsv` data and then used\n",
    "to time-align data from `initial_train_cs.tsv`.\n",
    "Following iterations refine the model on both datasets. The part coming from `initial_train_cs.tsv` is repeatedly re-aligned while the `manual_train.tsv` part is kept at the hand-made alignment. The details of the phone boundary positioning are thereby anchored to the human made examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc5b785",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74823cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_cv = 'initial_train_cs.tsv'# no phone targets in this tsv yet\n",
    "infile_man = 'manual_train.tsv' # manually labeled phones and their time boundaries\n",
    "\n",
    "sideview = 9 # how many additional MFCC frames before and after the focus point are seen\n",
    "mid_size = 100\n",
    "filename_base_base = \"man_both_training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6020ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.path[0] != '..':\n",
    "    sys.path[0:0] = ['..'] # prepend main Prak directory\n",
    "from prongen.hmm_pron import *\n",
    "from acmodel.praat_ifc import *\n",
    "from acmodel.nn_acmodel import *\n",
    "import acmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c34a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device = \"cpu\"\n",
    "acmodel.nn_acmodel.device = device\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954f3e19",
   "metadata": {},
   "source": [
    "## Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac25fe2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cv = pd.read_csv(infile_cv, sep=\"\\t\", keep_default_na=False)\n",
    "hmms_cv = get_training_hmms(infile_cv, derivatives=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cef12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_man = pd.read_csv(infile_man, sep=\"\\t\", keep_default_na=False)\n",
    "hmms_man = get_training_hmms(infile_man, derivatives=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc8634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5dadbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmms = hmms_man+hmms_cv # hmms_man should be the first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hmm in hmms:\n",
    "    triple_hmm_states(hmm) # Upgrade to 3 states per phone (just for duration, b() is still shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b75efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pro-forma targets, will not be used in this variant of training\n",
    "for hmm in hmms_cv:\n",
    "    create_start_targets(hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_log_corr = b_log_corrections(infile_man, b_set=b_set) # get b() corrections based on frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610de62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935360ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_size = len(b_set)\n",
    "in_size = hmms[0].mfcc.size(1)\n",
    "\n",
    "\" \".join(b_set), out_size, in_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04035f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO THIS NOW, mfccs are modified below!\n",
    "# (we use tricky way to access mfcc in training, different from the inference time)\n",
    "all_mfcc, all_targets = collect_training_material(hmms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4b3169",
   "metadata": {},
   "source": [
    "## Add speaker vectors (mean cepstra in 4 energy bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b9cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make s-vectors\n",
    "all_speaker_vectors_refs = []\n",
    "for hmm in hmms:\n",
    "    hmm.speaker_vector = mfcc_make_speaker_vector(hmm.mfcc)\n",
    "    ref = hmm.speaker_vector.to(device)\n",
    "    all_speaker_vectors_refs += [ref]*len(hmm.mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3256bf7b",
   "metadata": {},
   "source": [
    "## Changes for the Window-to-MFCC input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b4f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = hmms[0].mfcc.size(1) * (sideview+1+sideview) + 4*13 # added s-vector\n",
    "in_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c6ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for alignment decoding, change mfcc in all hmms (for training, we already have a copy)\n",
    "# NOTE: Make speaker vectors BEFORE this!\n",
    "for hmm in hmms:\n",
    "    hmm.mfcc = mfcc_win_view(mfcc_add_sideview(hmm.mfcc, sideview=sideview), sideview=sideview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc58a81",
   "metadata": {},
   "source": [
    "## Setup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a7ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(in_size, out_size, mid_size).to(device) # 50 20 100=svec 50=sv50\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "training_data = SpeechDataset(all_mfcc, all_targets, b_set, sideview=sideview, speaker_vectors=all_speaker_vectors_refs) # initial alignment\n",
    "training_data.ignored_end = len(\"\".join([hmm.targets for hmm in hmms_cv])) # first train without cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec4bf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for mega_epoch in range(1, 50): # starting from 1 as we have zero tsv\n",
    "    print(f\"======= Train {filename_base_base}, Epoch {mega_epoch} ========\")\n",
    "    print(f\"{len(training_data)=}\")\n",
    "\n",
    "    all_targets = \"\".join([hmm.targets for hmm in hmms])  # collect alignments\n",
    "    training_data.all_targets = all_targets  # just update the object with new targets\n",
    "\n",
    "    train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True) # new dataloader for this alignment\n",
    "\n",
    "    train_n_epochs(train_dataloader, optimizer, model, criterion, 20 if mega_epoch==1 else 5)\n",
    "    \n",
    "    filename_base = f\"{filename_base_base}_{'%04d' % mega_epoch}\"\n",
    "    torch.save(model.state_dict(), filename_base+\".pth\")\n",
    "    \n",
    "    training_data.ignored_end = 0 # Use both man+cv data for all the following training\n",
    "    print('Interrupted training for re-alignment...')\n",
    "\n",
    "    model.eval() # switch to evaluation mode\n",
    "\n",
    "    for idx, hmm in enumerate(hmms_cv): # aligning CV part, NOT the manually aligned part\n",
    "        if idx%1000==0:\n",
    "            print(f\"Align {idx}\")   \n",
    "        alp = align_hmm(hmm, model, b_set, b_log_corr=b_log_corr, group_tripled=True)\n",
    "\n",
    "    df_cv['targets'] = [hmm.targets for hmm in hmms_cv]\n",
    "    df = pd.concat([df_man, df_cv])\n",
    "    df.to_csv(filename_base+\".tsv\", sep=\"\\t\", index=False)\n",
    "    \n",
    "    b_log_corr = b_log_corrections(filename_base+\".tsv\", b_set=b_set) # get new b() corrections based on frequency"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
