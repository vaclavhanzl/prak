{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df3fd3f5",
   "metadata": {},
   "source": [
    "# Prepare Manually Aligned Training Data\n",
    "This notebooks prepares Prak training data from a manually phone-level time-aligned corpus.\n",
    "While it is posible to train Prak acousting model from just corresponding texts and\n",
    "recordings (e.g. using a CommonVoice corpus), adding some manually aligned phones\n",
    "helps to teach the model where exactly we want to put the phone boundaries (this is rather\n",
    "subjective so we have to provide an example of what we want).\n",
    "\n",
    "For example, [Fonetický ústav FFUK](https://fonetika.ff.cuni.cz/) invested great deal of\n",
    "human labor into preparation of such manually alligned corpus.\n",
    "If you use models trained on their data, please give FÚ a due credit.\n",
    "\n",
    "This notebook converts TextGrid files to a time aligned tsv file usable in Prak training.\n",
    "Format of this file is the same as the format of intermediate tsv files produced during\n",
    "Prak training on the CommonVoice (only sentence-level time aligned) data.\n",
    "The difference is that this notebook assignes phone labels to 10ms intervals in audio\n",
    "based on a human decision (from the TextGrid file) while the tsv produced during\n",
    "CommonVoice training has this assignment done by the partially trained NN itself.\n",
    "\n",
    "Human-aligned utf8 coded files should be named ```*.TextGrid``` and have a \n",
    "corresponding ```*.wav``` files in the same directory. There can be any directory\n",
    "structure but filenames (without path) should be unique in the full data set.\n",
    "\n",
    "TextGrid files should contain:\n",
    "* interval tier named ```phone``` or ```Phone``` with individual phones in [Czech SAMPA](https://www.phon.ucl.ac.uk/home/sampa/czech-uni.htm)\n",
    "* interval tier named ```word``` or ```Word``` which will be used as transcript of the recording\n",
    "\n",
    "The ```word``` tier is not strictly needed but makes tsv easier to check and could be used to fix little errors in the ```phone``` tier (e.g. phones which are out of the Czech SAMPA set can be replaced with a prediction made by Prak). We are in fact interested in the ```phrase``` tier but it is not consistently present in the FÚ data. Also, ```word``` tends to have corrections where reader diverged from the prompt, unlike ```phrase```.\n",
    "\n",
    "When the manually aligned TextGrid contains phones out of the expected set, we use Prak alignment data (made by CV-trained model) as a backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ab999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config cell - edit paths as needed\n",
    "\n",
    "# Where is the corpus:\n",
    "full_data = \"/data/ada/000_cleanTG\"\n",
    "\n",
    "# Where is our test subset of the full corpus (to be excluded from train):\n",
    "test_subset = \"/home/hanzl/test-prak/ref2/repair\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc9d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "if sys.path[0] != '..':\n",
    "    sys.path[0:0] = ['..'] # prepend main Prak directory\n",
    "from acmodel.praat_ifc import (\n",
    "    read_interval_tiers_from_textgrid_file,\n",
    "    rename_prune_tiers,\n",
    "    desampify_phone_tier)\n",
    "from acmodel.nn_acmodel import (\n",
    "    load_nn_acoustic_model,\n",
    "    b_log_corrections,\n",
    "    triple_hmm_states,\n",
    "    mfcc_make_speaker_vector,\n",
    "    mfcc_win_view,\n",
    "    mfcc_add_sideview,\n",
    "    b_set,\n",
    "    align_hmm)\n",
    "from prongen.hmm_pron import HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc9c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_wav_paths = !find {full_data} -name \"*.wav\"\n",
    "test_wav_paths = !find {test_subset} -name \"*.wav\"\n",
    "len(full_wav_paths), len(test_wav_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b1f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav2path = {path.split(\"/\")[-1]: path for path in full_wav_paths}\n",
    "assert len(wav2path)==len(full_wav_paths) # make sure file names are all different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a4b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wav_file_set = {path.split(\"/\")[-1] for path in test_wav_paths}\n",
    "assert len(test_wav_file_set)==len(test_wav_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_wav_file_set = set(wav2path) # get just keys, i.e. file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e94a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wav_file_set = full_wav_file_set-test_wav_file_set\n",
    "assert len(train_wav_file_set)==len(full_wav_file_set)-len(test_wav_file_set)\n",
    "# The assert above is not strictly necessary but would reveal\n",
    "# any test files not being present in the full set. Comment it out\n",
    "# if your test set also contains files comming from elsewhere.\n",
    "len(train_wav_file_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone_tier_to_phone_targets(frames, phone_tier):\n",
    "    \"\"\"\n",
    "    Create targets for individual 10ms frames from a list\n",
    "    of phone intervals. Be permissive when phone times do not\n",
    "    fit but print a warning.\n",
    "    \"\"\"\n",
    "    targets = ['|']*frames\n",
    "    # fill in targets for individual phones:\n",
    "    for (b, e, p) in phone_tier:\n",
    "        if p=='':\n",
    "            continue # likely silence, we have it pre-filled already\n",
    "        #     +----------------+   <-phone\n",
    "        #+-----+=====+=====+=====+-----+-----+-----+   == phone's frames\n",
    "        #0    0.01  0.02  0.03      time axis\n",
    "        #  \n",
    "        b_frame = int(b*100+0.5) # first frame which belongs to this phone\n",
    "        e_frame = int(e*100+0.501) # first frame which does NOT belong to this phone\n",
    "        # 0.5 vs 0.501 makes sure we do not leave frame empty due to rounding noise\n",
    "        for f in range(b_frame, e_frame):\n",
    "            if f>=0 and f<frames:\n",
    "                targets[f]=p\n",
    "    return ''.join(targets)\n",
    "\n",
    "#phone_tier_to_phone_targets(7, []) # '|||||||'\n",
    "#phone_tier_to_phone_targets(7, [(0.00, 0.01, 's')]) # 's||||||'\n",
    "#phone_tier_to_phone_targets(7, [(0.00, 0.014999, 's'), (0.0150001, 0.03, 'z')]) # 'ssz||||'\n",
    "#phone_tier_to_phone_targets(7, [(-3, 10, 's')]) # 'sssssss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf699ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare CV-trained model for eventual patching of problematic spots\n",
    "# where human put a non-existing phone.\n",
    "\n",
    "model = load_nn_acoustic_model(\"half\", mid_size=100, varstates=False)\n",
    "b_log_corr = b_log_corrections(\"half.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dde74a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare tsv columns\n",
    "c_wav = []\n",
    "c_sentence = []\n",
    "c_targets = []\n",
    "fixes = 0\n",
    "for wav in sorted(train_wav_file_set):\n",
    "    path = wav2path[wav]\n",
    "    tg_path = path[:-len(\".wav\")]+\".TextGrid\"\n",
    "    #print(tg_path)\n",
    "    in_tiers_all = read_interval_tiers_from_textgrid_file(tg_path)\n",
    "    in_tiers = rename_prune_tiers(in_tiers_all, [\"word\", \"Word:word\", \"phone\", \"Phone:phone\"])\n",
    "    assert set(in_tiers.keys())=={\"phone\", \"word\"}\n",
    "    txt = \" \".join(x for (b, e, w) in in_tiers[\"word\"] if (x:=w.strip())!=\"\")\n",
    "    in_tiers[\"phone\"] = desampify_phone_tier(in_tiers[\"phone\"])\n",
    "    c_wav.append(path)\n",
    "    c_sentence.append(txt)\n",
    "    # compute MFCC from wav, just to find out number of segments:\n",
    "    hmm = HMM(txt, path, derivatives=0)\n",
    "    frames = len(hmm.mfcc)\n",
    "    targets = phone_tier_to_phone_targets(frames, in_tiers[\"phone\"])\n",
    "    \n",
    "    if '#' in targets or '@' in targets:  # 394 files out of 1435 has #\n",
    "        fixes += 1\n",
    "        #print(f\"replacing targets {targets}\")\n",
    "        \n",
    "        # finish automatic alignement setup:\n",
    "        triple_hmm_states(hmm)\n",
    "        hmm.speaker_vector = mfcc_make_speaker_vector(hmm.mfcc)\n",
    "        hmm.mfcc = mfcc_win_view(mfcc_add_sideview(hmm.mfcc))\n",
    "    \n",
    "        targets = list(targets) # make characters assignable\n",
    "        alp = align_hmm(hmm, model, b_set, b_log_corr=b_log_corr)\n",
    "        for i in range(frames):\n",
    "            if targets[i] in '#@':\n",
    "                targets[i] = hmm.targets[i] # STILL LOOSING EXACT TIME BOUNDARY...\n",
    "        targets = ''.join(targets) # back to a string\n",
    "        \n",
    "        #print(f\" with new targets {targets}\")\n",
    "    \n",
    "    c_targets.append(targets)\n",
    "    \n",
    "fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242d9629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(c_wav, c_sentence, c_targets)), columns=['wav', 'sentence', 'targets'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"manual_train.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5019c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head manual_train.tsv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
